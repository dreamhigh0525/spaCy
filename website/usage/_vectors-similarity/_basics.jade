//- ðŸ’« DOCS > USAGE > VECTORS & SIMILARITY > BASICS

+aside("Training word vectors")
    |  Dense, real valued vectors representing distributional similarity
    |  information are now a cornerstone of practical NLP. The most common way
    |  to train these vectors is the #[+a("https://en.wikipedia.org/wiki/Word2vec") word2vec]
    |  family of algorithms. The default
    |  #[+a("/models/en") English model] installs
    |  300-dimensional vectors trained on the
    |  #[+a("http://commoncrawl.org") Common Crawl] corpus.
    |  If you need to train a word2vec model, we recommend the implementation in
    |  the Python library #[+a("https://radimrehurek.com/gensim/") Gensim].

include ../_spacy-101/_similarity
include ../_spacy-101/_word-vectors
